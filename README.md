# Unified Multimodal Painting Style Generator

This project trains a custom LoRA (Low-Rank Adaptation) model to apply a unique "painting" style to images generated by Stable Diffusion. It also trains a captioner model that generates a descriptive caption for the stylized image. The final result is a Gradio web interface where a user can input a prompt and a seed to generate both a unique, stylized image and an accurate caption.


## Features

* **Custom Style Training:** Uses LoRA to efficiently train a specific artistic style on a base Stable Diffusion model.

* **Accurate Captioning:** Utilizes the powerful BLIP model to generate captions that accurately describe the final generated image.

* **Checkpointing:** The training process is robust, saving progress after each epoch to prevent data loss from session disconnections.

* **Interactive UI:** A simple and stylish Gradio web application allows for easy interaction with the final trained models.

* **Offline Inference:** After a one-time setup, the final Gradio application can be run completely offline on a local machine with a suitable GPU.

## Setup and Installation

Follow these steps to set up the environment and run the project on your local machine.

### 1. Clone the Repository

First, clone this repository to your local machine:

git clone https://github.com/adityajainuine/painting-style-generator.git
cd painting-style-generator


### 2. Set Up a Python Environment

It is highly recommended to use a virtual environment to manage dependencies.

Create a virtual environment

python -m venv venv

Activate the virtual environment

On Windows:

venv\Scripts\activate

On macOS/Linux:

source venv/bin/activate


### 3. Install Dependencies

Install all the required Python libraries using the `requirements.txt` file.

pip install -r requirements.txt


## How to Run

### 1. Download the Dataset

This model was trained on a dataset of ~2000 painting images. Due to its size, the dataset is not included in this repository.

* **Dataset:** You can use a dataset like the "Painter By Numbers" dataset from Kaggle or create your own collection of images.

* **Folder Structure:** Create a `datasets` folder in the root of the project, and inside it, create a `painting` folder. Place all your training images inside `painting`.

painting-style-generator/
├── datasets/
│   └── painting/
│       ├── 0001.jpg
│       └── 0002.jpg
└── ...


### 2. Place Your Trained Models

Place your pre-trained model files in the `models/` directory.

* `models/pytorch_lora_weights.safetensors`

* `models/captioner_model.pth`

If you want to train the model from scratch, you can run the `painting_style_trainer.ipynb` notebook.

### 3. Run the Gradio Application

To launch the interactive web UI, run the `app.py` script from your terminal.

python app.py


* **First Run:** The first time you run this, it will need an **internet connection** to download the base Stable Diffusion and BLIP models (several gigabytes). These will be cached on your computer.

* **Offline Use:** After the first run, you can run the application **completely offline**.

Open your web browser and navigate to the local URL provided in the terminal
